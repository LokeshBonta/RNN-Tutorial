{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Language Class\n",
    "\n",
    "Parameters:\n",
    "1. word2index dict\n",
    "2. index2word dict\n",
    "3. word2count dict - to filter-out infrequent words\n",
    "4. n_count variable - for counting number of unique words in the language\n",
    "\n",
    "Input:\n",
    "\n",
    "1. Name of the Language -> French/English etc\n",
    "\n",
    "Methods:\n",
    "\n",
    "1. addSentence using addWord\n",
    "2. addWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2 #Including SOS and EOS token for each language\n",
    "    \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2count[word] = 1\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else :\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for String Preprocessing\n",
    "\n",
    "This module is already completed. This is basic string processing in python using regex and inbuilt utility functions\n",
    "\n",
    "1. Convert string to lowerCase\n",
    "2. remove leading or trailing spaces - use strip()\n",
    "3. Convert all UniCode to ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Note: The data is present in eng-fra.txt file. You need to load the data using the following steps\n",
    "\n",
    "1. Load data from file, removing spaces and splitting by new-line\n",
    "2. Each line has 2 parts:\n",
    "    1. The french text\n",
    "    2. Tab separation '\\t'\n",
    "    3. The English translation\n",
    "    \n",
    "3. Use normalize each of the strings and create pairs of sentences.\n",
    "4. define a language model\n",
    "5. Return input_lang,output_lang and the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed to 10853 sentence pairs\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['vous etes plus grande que moi .', 'you are taller than me .']\n"
     ]
    }
   ],
   "source": [
    "def readLangs(lang1,lang2):\n",
    "    f = open('data/LSTM/eng-fra.txt', encoding='utf-8').read().strip().split(\"\\n\")\n",
    "    \n",
    "    pairs = [[normalizeString(p) for p in line.split('\\t')] for line in f]\n",
    "    \n",
    "    pairs = [list(reversed(p)) for p in pairs]\n",
    "    input_lang = Lang(lang2)\n",
    "    output_lang = Lang(lang1)\n",
    "    \n",
    "    return input_lang,output_lang,pairs\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p): # boolean function. True -> keep the pair, False ->discard\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1,lang2):\n",
    "    input_lang,output_lang,pairs = readLangs(lang1,lang2)\n",
    "    pairs = filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang,output_lang,pairs\n",
    "\n",
    "input_lang,output_lang,pairs = prepareData('eng','fra')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "<img src =\"images/lstm2.png\">\n",
    "\n",
    "We are going to simulate the network shown above. It consists of 2 stages. One is the encoding phase and other is the decoding phase..\n",
    "\n",
    "The Encode Module is going to follow the network structure given below. The purpose of encoder is 2 folds:\n",
    "\n",
    "1. Outputs some value for every word in the input sequence\n",
    "2. For every input word - output a vector and a hidden state.\n",
    "\n",
    "This hidden state is used as \"input\" for the word of the input sequence.\n",
    "\n",
    "<img src = \"images/lstm1.png\" >\n",
    "\n",
    "Here, we are using a differen type of RNNCell - called the GRU (Gated Recurrent Unit). It is a very popular variant of LSTM Cell.\n",
    "\n",
    "Please fill in the code below to build the encoder network. You need to fill in the RHS of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,n_layers=1):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        \n",
    "        # define hidden size\n",
    "        self.hidden_size = hidden_size\n",
    "        # define n_layers\n",
    "        self.n_layers = n_layers\n",
    "        # define an embedding from input_size to hidden_size\n",
    "        self.embedding = nn.Embedding(input_size,hidden_size)\n",
    "        # gru from hidden to hidden (hidden of embedding to output-hidden)\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "        \n",
    "    def forward(self,input,hidden):\n",
    "        # map embedding and reshape it to (1,1,-1) shape (seq_len,batch_Size and input_size)\n",
    "        embedded = self.embedding(input).view(1,1,-1) #seq_len,batch_size = 1\n",
    "        # save embedded in variable output\n",
    "        output = embedded\n",
    "        # for each gru layer - by default it is 1\n",
    "        for i in range(self.n_layers):\n",
    "            # output,hidden hold the return values from gru cell\n",
    "            output,hidden = self.gru(output,hidden)\n",
    "        \n",
    "        # return output and hidden after each forward pass\n",
    "        return output,hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # return hidden layer values - zeros of size (1,1,hidden_size)\n",
    "        result = Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "\n",
    "<img src=\"images/lstm2.png\">\n",
    "\n",
    "Decoder is another RNN that takes encoders output vector/vectors and maps it to a sequence of words (translation)\n",
    "\n",
    "It takes the \"Context Vector\" from the encoder - the last output vector from the encoder module as its initial hidden state\n",
    "\n",
    "At every step, it is given an input token and a hidden state. Initial state is <SOS> token and the hidden state is the context vector from encoder (its last hidden state)\n",
    "\n",
    "<img src = \"images/lstm3.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size,n_layers=1):\n",
    "        super(DecoderRNN,self).__init__()\n",
    "        # define hidden size\n",
    "        self.hidden_size = hidden_size\n",
    "        # define n_layers\n",
    "        self.n_layers = n_layers\n",
    "        # define embedding taking output_size to hidden size\n",
    "        self.embedding = nn.Embedding(output_size,hidden_size)\n",
    "        # gru cell to take hidden to hidden!\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "        # linear from hidden to output size\n",
    "        self.out = nn.Linear(hidden_size,output_size)\n",
    "        # softmax classification - for prob of next word\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self,input,hidden):\n",
    "        # map input (which is encoder output) to (seq_len,batch_size,input_size) using embedding\n",
    "        output = self.embedding(input).view(1,1,-1) #seq_len,batch_size = 1,1\n",
    "        # for each of the gru layers\n",
    "        for i in range(self.n_layers):\n",
    "            # relu your output\n",
    "            output = F.relu(output)\n",
    "            # apply gru unit on output,hidden for next_level output,hidden\n",
    "            output,hidden = self.gru(output,hidden)\n",
    "        # apply softmax on the linear embedding of output[0]\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        # return output,hidden for next iteration\n",
    "        return output,hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data\n",
    "\n",
    "You have pairs [ french_Sentence, English_sentence]. We now need one-hot representation of each of these sentences, w.r.t to their own respective vocabularies. This module will focus on preparing you training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a sentence from language convert to a index-vector\n",
    "def indexesFromSentence(lang,sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "# convert the index-vector to tensor\n",
    "def variableFromSentence(lang,sentence):\n",
    "    indexes = indexesFromSentence(lang,sentence)\n",
    "    # add EOS flag\n",
    "    indexes.append(EOS_token)\n",
    "    # longTensor(index).view(-1,1) -> a column vector\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1,1))\n",
    "\n",
    "    return result\n",
    "\n",
    "def variableFromPair(pair):\n",
    "    # construct tensors for input and target for every pait\n",
    "    input_variable = variableFromSentence(input_lang,pair[0])\n",
    "    target_variable = variableFromSentence(output_lang,pair[1])\n",
    "    return input_variable,target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     6\n",
       "   298\n",
       "    11\n",
       "   247\n",
       "    14\n",
       "   100\n",
       "   101\n",
       "   365\n",
       "     5\n",
       "     1\n",
       " [torch.LongTensor of size 10x1], Variable containing:\n",
       "    2\n",
       "    3\n",
       "  148\n",
       "   57\n",
       "    4\n",
       "    1\n",
       " [torch.LongTensor of size 6x1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variableFromPair(pairs[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "Now that we have defined our model, we need to train it to be able to perform seq2seq translation. The overview of the training process is as follows:\n",
    "\n",
    "1. Initialize hidden_layers with zeros\n",
    "2. Zero grad optimizers for both Encoder and Decoder RNN (Remember - there are 2 RNNs for each iteration)\n",
    "3. Define input and target lengths\n",
    "4. Define loss = 0\n",
    "\n",
    "## EncoderRNN Training\n",
    "\n",
    "1. For each word in the input sentence, pass it through the encoder\n",
    "2. Output of each time-step becomes the input for the next time-step\n",
    "\n",
    "\n",
    "<img src=\"images/lstm2.png\">\n",
    "\n",
    "Please complete the below module as per the steps given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Forcing Network\n",
    "\n",
    "It is just a fancy name for using taget variable as input to decoder instead of hidden layer value from encoder..\n",
    "2 things to remember in this conext:\n",
    "\n",
    "1. There is a propotion w.r.t to using tearching forcing targets as decoder inputs.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_variable,target_variable,encoder,decoder,encoder_optimizer,decoder_optimizer, criterion):\n",
    "    \n",
    "    # initialize encode hidden\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    # zero-out gradient for encoder and decoder optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # compute input and target length\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    # intialize loss to 0\n",
    "    loss = 0\n",
    "    # for each input index\n",
    "    for ei in range(input_length):\n",
    "        #pass it to the encoder with the hidden state\n",
    "        encoder_output,encoder_hidden = encoder(input_variable[ei],encoder_hidden)\n",
    "    \n",
    "    # append decoder input with sos-token\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    # decoder hidden will be encoder hidden\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # define teacher_forcing ratio and set flag\n",
    "    use_teacher_forcing = True if random.random()<.5 else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # for each till target length\n",
    "        for di in range(target_length):\n",
    "            # pass input and hidden throught the decoder\n",
    "            decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "            # compute loss ,using deoder output and target variable\n",
    "            loss += criterion(decoder_output,target_variable[di])\n",
    "            # set input as targer variable\n",
    "            decoder_input = target_variable[di]\n",
    "    else:   \n",
    "        for di in range(target_length):\n",
    "            # pass input and hidden through the decoder\n",
    "            decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "            # find index of maximun using decoder_output probabilities\n",
    "            topv,topi = decoder_output.data.topk(1)\n",
    "            next_index = topi[0][0]\n",
    "            # decoder input is the next variable Tensor\n",
    "            decoder_input = Variable(torch.LongTensor([[next_index]]))\n",
    "            # add to loss.. wait! dont backprop till the decoder computation is complete\n",
    "            loss += criterion(decoder_output,target_variable[di])\n",
    "            # if index is same as end of sentence then break!\n",
    "            if next_index==EOS_token:\n",
    "                break\n",
    "\n",
    "   # back propagate loss\n",
    "    loss.backward()\n",
    "    # step optimizer\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #return loss (normalized loss)\n",
    "    return loss.data[0]/target_length\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder,decoder,n_iter,print_every=1000,learning_rate = .01):\n",
    "    plot_loss = []\n",
    "    print_loss = 0\n",
    "    # define optimizers - encoder and decoder opts\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(),lr = learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(),lr = learning_rate)\n",
    "    # generate random pairs..\n",
    "    training_set = [variableFromPair(random.choice(pairs)) for i in range(n_iter)]\n",
    "    # define NLLoss as loss criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    # for number of iterations\n",
    "    for i in range(1,n_iter+1):\n",
    "        # extract the input sentence\n",
    "        train_sentence = training_set[i-1]\n",
    "        # define input and target variable\n",
    "        input_variable = train_sentence[0]\n",
    "        target_variable = train_sentence[1]\n",
    "        # call train utilities\n",
    "        loss = train(input_variable,target_variable,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion)\n",
    "        # add loss\n",
    "        print_loss += loss\n",
    "        \n",
    "        if i%print_every==0:\n",
    "            avg_loss = print_loss/print_every\n",
    "            print (\"Iteration %d and Loss %f\" % (i,avg_loss))\n",
    "            print_loss = 0\n",
    "            plot_loss.append(avg_loss)\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # show loss plot\n",
    "    plt.plot(plot_loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 and Loss 3.471181\n",
      "Iteration 2000 and Loss 3.044145\n",
      "Iteration 3000 and Loss 2.860929\n",
      "Iteration 4000 and Loss 2.742590\n",
      "Iteration 5000 and Loss 2.612650\n",
      "Iteration 6000 and Loss 2.487397\n",
      "Iteration 7000 and Loss 2.453658\n",
      "Iteration 8000 and Loss 2.361946\n",
      "Iteration 9000 and Loss 2.333279\n",
      "Iteration 10000 and Loss 2.220161\n",
      "Iteration 11000 and Loss 2.225520\n",
      "Iteration 12000 and Loss 2.110374\n",
      "Iteration 13000 and Loss 2.020653\n",
      "Iteration 14000 and Loss 2.023576\n",
      "Iteration 15000 and Loss 1.976859\n",
      "Iteration 16000 and Loss 1.902545\n",
      "Iteration 17000 and Loss 1.854898\n",
      "Iteration 18000 and Loss 1.845379\n",
      "Iteration 19000 and Loss 1.746475\n",
      "Iteration 20000 and Loss 1.740496\n",
      "Iteration 21000 and Loss 1.671627\n",
      "Iteration 22000 and Loss 1.640360\n",
      "Iteration 23000 and Loss 1.606424\n",
      "Iteration 24000 and Loss 1.609043\n",
      "Iteration 25000 and Loss 1.531879\n",
      "Iteration 26000 and Loss 1.541645\n",
      "Iteration 27000 and Loss 1.441238\n",
      "Iteration 28000 and Loss 1.438794\n",
      "Iteration 29000 and Loss 1.321520\n",
      "Iteration 30000 and Loss 1.327720\n",
      "Iteration 31000 and Loss 1.373613\n",
      "Iteration 32000 and Loss 1.332231\n",
      "Iteration 33000 and Loss 1.303774\n",
      "Iteration 34000 and Loss 1.222055\n",
      "Iteration 35000 and Loss 1.230011\n",
      "Iteration 36000 and Loss 1.188762\n",
      "Iteration 37000 and Loss 1.169124\n",
      "Iteration 38000 and Loss 1.169797\n",
      "Iteration 39000 and Loss 1.092996\n",
      "Iteration 40000 and Loss 1.021798\n",
      "Iteration 41000 and Loss 1.067132\n",
      "Iteration 42000 and Loss 1.030920\n",
      "Iteration 43000 and Loss 1.010438\n",
      "Iteration 44000 and Loss 0.997130\n",
      "Iteration 45000 and Loss 0.956412\n",
      "Iteration 46000 and Loss 0.948764\n",
      "Iteration 47000 and Loss 0.925258\n",
      "Iteration 48000 and Loss 0.916110\n",
      "Iteration 49000 and Loss 0.875070\n",
      "Iteration 50000 and Loss 0.887313\n",
      "Iteration 51000 and Loss 0.878656\n",
      "Iteration 52000 and Loss 0.809442\n",
      "Iteration 53000 and Loss 0.855140\n",
      "Iteration 54000 and Loss 0.796951\n",
      "Iteration 55000 and Loss 0.809146\n",
      "Iteration 56000 and Loss 0.770406\n",
      "Iteration 57000 and Loss 0.714839\n",
      "Iteration 58000 and Loss 0.749737\n",
      "Iteration 59000 and Loss 0.683888\n",
      "Iteration 60000 and Loss 0.726360\n",
      "Iteration 61000 and Loss 0.696049\n",
      "Iteration 62000 and Loss 0.637656\n",
      "Iteration 63000 and Loss 0.683924\n",
      "Iteration 64000 and Loss 0.639720\n",
      "Iteration 65000 and Loss 0.654455\n",
      "Iteration 66000 and Loss 0.633294\n",
      "Iteration 67000 and Loss 0.624243\n",
      "Iteration 68000 and Loss 0.604708\n",
      "Iteration 69000 and Loss 0.562594\n",
      "Iteration 70000 and Loss 0.578287\n",
      "Iteration 71000 and Loss 0.579140\n",
      "Iteration 72000 and Loss 0.568954\n",
      "Iteration 73000 and Loss 0.518681\n",
      "Iteration 74000 and Loss 0.549428\n",
      "Iteration 75000 and Loss 0.464549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c5c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c5f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words,hidden_size)\n",
    "decoder = DecoderRNN(hidden_size,output_lang.n_words)\n",
    "\n",
    "trainIters(encoder,decoder,n_iter=75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluatePair(encoder,decoder,sentence,max_length = 10):\n",
    "    input_variable = variableFromSentence(input_lang,sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output,encoder_hidden = encoder(input_variable[ei],encoder_hidden)\n",
    "    \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoder_words = []\n",
    "    \n",
    "    for di in range(max_length):\n",
    "        decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        next_index = topi[0][0]\n",
    "        \n",
    "        if next_index==EOS_token:\n",
    "            decoder_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoder_words.append(output_lang.index2word[next_index])\n",
    "            \n",
    "        decoder_input = Variable(torch.LongTensor([[next_index]]))\n",
    "    \n",
    "    return decoder_words\n",
    "\n",
    "def evaluate(encoder,decoder,n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print (\"Input: \",pair[0])\n",
    "        print (\"Ground Truth: \",pair[1])\n",
    "        output_words = evaluatePair(encoder,decoder,pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print (\"Translation: \",output_sentence)\n",
    "        print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  je suis trop vieux pour aller en allemagne .\n",
      "Ground Truth:  i m too old to go to germany .\n",
      "Translation:  i m too old to go to go . <EOS>\n",
      "\n",
      "\n",
      "\n",
      "Input:  vous ne convenez pas .\n",
      "Ground Truth:  you re not fit .\n",
      "Translation:  you re not paying . <EOS>\n",
      "\n",
      "\n",
      "\n",
      "Input:  tu es seule n est ce pas ?\n",
      "Ground Truth:  you re alone aren t you ?\n",
      "Translation:  you re impressed aren t you ? <EOS>\n",
      "\n",
      "\n",
      "\n",
      "Input:  je ne vous en empeche pas .\n",
      "Ground Truth:  i m not stopping you .\n",
      "Translation:  i m not listening you . <EOS>\n",
      "\n",
      "\n",
      "\n",
      "Input:  il est une autorite reconnue sur le sujet .\n",
      "Ground Truth:  he is a recognized authority on the subject .\n",
      "Translation:  he is a member authority on the subject . <EOS>\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(encoder,decoder,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
