{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Seq2Seq Translation!\n",
    "\n",
    "As part of understanding LSTMs, we will build Seq2Seq translator for translating French to English.\n",
    "\n",
    "In this module, we seek to understand and implement Attention Transfer for learning Seq2Seq translation\n",
    "\n",
    "Just as in the previous assignments, please follow along the instructions provided in the cells/comments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Language Class\n",
    "\n",
    "Parameters:\n",
    "1. word2index dict\n",
    "2. index2word dict\n",
    "3. word2count dict - to filter-out infrequent words\n",
    "4. n_count variable - for counting number of unique words in the language\n",
    "\n",
    "Input:\n",
    "\n",
    "1. Name of the Language -> French/English etc\n",
    "\n",
    "Methods:\n",
    "\n",
    "1. addSentence using addWord\n",
    "2. addWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2 #Including SOS and EOS token for each language\n",
    "    \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2count[word] = 1\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else :\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for String Preprocessing\n",
    "\n",
    "This module is already completed. This is basic string processing in python using regex and inbuilt utility functions\n",
    "\n",
    "1. Convert string to lowerCase\n",
    "2. remove leading or trailing spaces - use strip()\n",
    "3. Convert all UniCode to ASCII Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Note: The data is present in eng-fra.txt file. You need to load the data using the following steps\n",
    "\n",
    "1. Load data from file, removing spaces and splitting by new-line\n",
    "2. Each line has 2 parts:\n",
    "    1. The french text\n",
    "    2. Tab separation '\\t'\n",
    "    3. The English translation\n",
    "    \n",
    "3. Use normalize each of the strings and create pairs of sentences.\n",
    "4. define a language model\n",
    "5. Return input_lang,output_lang and the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed to 10853 sentence pairs\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['tu es un idiot .', 'you re an idiot .']\n"
     ]
    }
   ],
   "source": [
    "def readLangs(lang1,lang2):\n",
    "    f = open('data/LSTM/eng-fra.txt', encoding='utf-8').read().strip().split(\"\\n\")\n",
    "    \n",
    "    pairs = [[normalizeString(p) for p in line.split('\\t')] for line in f]\n",
    "    \n",
    "    pairs = [list(reversed(p)) for p in pairs]\n",
    "    input_lang = Lang(lang2)\n",
    "    output_lang = Lang(lang1)\n",
    "    \n",
    "    return input_lang,output_lang,pairs\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p): # boolean function. True -> keep the pair, False ->discard\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1,lang2):\n",
    "    input_lang,output_lang,pairs = readLangs(lang1,lang2)\n",
    "    pairs = filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang,output_lang,pairs\n",
    "\n",
    "input_lang,output_lang,pairs = prepareData('eng','fra')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "<img src =\"images/lstm2.png\">\n",
    "\n",
    "We are going to simulate the network shown above. It consists of 2 stages. One is the encoding phase and other is the decoding phase..\n",
    "\n",
    "The Encode Module is going to follow the network structure given below. The purpose of encoder is 2 folds:\n",
    "\n",
    "1. Outputs some value for every word in the input sequence\n",
    "2. For every input word - output a vector and a hidden state.\n",
    "\n",
    "This hidden state is used as \"input\" for the word of the input sequence.\n",
    "\n",
    "<img src = \"images/lstm1.png\" >\n",
    "\n",
    "Here, we are using a differen type of RNNCell - called the GRU (Gated Recurrent Unit). It is a very popular variant of LSTM Cell.\n",
    "\n",
    "Please fill in the code below to build the encoder network. You need to fill in the RHS of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,n_layers=1):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        \n",
    "        # define hidden size\n",
    "        self.hidden_size = hidden_size\n",
    "        # define n_layers\n",
    "        self.n_layers = n_layers\n",
    "        # define an embedding from input_size to hidden_size\n",
    "        self.embedding = nn.Embedding(input_size,hidden_size)\n",
    "        # gru from hidden to hidden (hidden of embedding to output-hidden)\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "        \n",
    "    def forward(self,input,hidden):\n",
    "        # map embedding and reshape it to (1,1,-1) shape (seq_len,batch_Size and input_size)\n",
    "        embedded = self.embedding(input).view(1,1,-1) #seq_len,batch_size = 1\n",
    "        # save embedded in variable output\n",
    "        output = embedded\n",
    "        # for each gru layer - by default it is 1\n",
    "        for i in range(self.n_layers):\n",
    "            # output,hidden hold the return values from gru cell\n",
    "            output,hidden = self.gru(output,hidden)\n",
    "        \n",
    "        # return output and hidden after each forward pass\n",
    "        return output,hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # return hidden layer values - zeros of size (1,1,hidden_size)\n",
    "        result = Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Decoder\n",
    "\n",
    "<img src=\"images/lstm2.png\">\n",
    "\n",
    "Decoder is another RNN that takes encoders output vector/vectors and maps it to a sequence of words (translation)\n",
    "\n",
    "It takes the \"Context Vector\" from the encoder - the last output vector from the encoder module as its initial hidden state. At every step, it is given an input token and a hidden state. Initial state is <SOS> token and the hidden state is the context vector from encoder (its last hidden state)\n",
    "\n",
    "# Attention Overview\n",
    "<img src = \"images/lstm5.png\">\n",
    "\n",
    "Please read this link - this is the best link I got online for Attention Transfer.\n",
    "\n",
    "Link: https://distill.pub/2016/augmented-rnns/\n",
    "\n",
    "To give an overview, Attention transfer mainly deals with \"focusing\" on important factors. How does attention transfer happens?\n",
    "\n",
    "# Attention Module\n",
    "\n",
    "<img src = \"images/lstm4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size,n_layers=1,dropout_percent=.25,max_length=10):\n",
    "        super(AttentionDecoderRNN,self).__init__()\n",
    "        \n",
    "        # store hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # store output_size\n",
    "        self.output_size = output_size\n",
    "        # store n_layers\n",
    "        self.n_layers = n_layers\n",
    "        # store drop_out ratio\n",
    "        self.dropout_percent = dropout_percent\n",
    "        # store max_length\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # define embedding from output_size to hidden\n",
    "        self.embedding = nn.Embedding(output_size,hidden_size)\n",
    "        # linear embedding from 2*hidden_size to max_len - for attn weights\n",
    "        self.attn = nn.Linear(hidden_size*2,self.max_length)\n",
    "        # liear embedding from 2*hidden_size to hidden_size - decoder input\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
    "        #  nn.dropout for reducing 'instability'\n",
    "        self.dropout = nn.Dropout(self.dropout_percent)\n",
    "        # define gru from hidden_size to hidden_size\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "        # linear embedding from hidden_size to output_size\n",
    "        self.out = nn.Linear(hidden_size,output_size)\n",
    "    \n",
    "    def forward(self,input,hidden,encoder_output,encoder_outputs):\n",
    "        # call embedding utility and reshape it to (1,1,-1)\n",
    "        embedded = self.embedding(input).view(1,1,-1) #seq_len,batch_size = 1,1\n",
    "        # apply dropout on embedded\n",
    "        embedded = self.dropout(embedded)\n",
    "        # softmax of attn map of concat (hidden[0],embedded[0]) -> input and hidden concat\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((hidden[0],embedded[0]),1)))\n",
    "        # apply attention, using batch matrix multiply bmm on attn_weights and encoder_outputs, unsqueeze(0) dim\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        # concat embedded[0] with attention applied[0] in dim 1\n",
    "        output = torch.cat((embedded[0],attn_applied[0]),1)\n",
    "        # do a linear embedding of output to hidden_size using attn_combine\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        # for range in n_layers\n",
    "        for i in range(self.n_layers):\n",
    "            # F.relu on output - activation\n",
    "            output = F.relu(output)\n",
    "            # pass output variable and hidden as input to gru\n",
    "            output,hidden = self.gru(output,hidden)\n",
    "        # final output will be F.log_softmax of the linear embedding (self.out) on output[0] (last decoder output) \n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        # return output,hidden and attn_weights\n",
    "        return output,hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data\n",
    "\n",
    "You have pairs [ french_Sentence, English_sentence]. We now need one-hot representation of each of these sentences, w.r.t to their own respective vocabularies. This module will focus on preparing you training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a sentence from language convert to a index-vector\n",
    "def indexesFromSentence(lang,sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "# convert the index-vector to tensor\n",
    "def variableFromSentence(lang,sentence):\n",
    "    indexes = indexesFromSentence(lang,sentence)\n",
    "    # add EOS flag\n",
    "    indexes.append(EOS_token)\n",
    "    # longTensor(index).view(-1,1) -> a column vector\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1,1))\n",
    "\n",
    "    return result\n",
    "\n",
    "def variableFromPair(pair):\n",
    "    # construct tensors for input and target for every pait\n",
    "    input_variable = variableFromSentence(input_lang,pair[0])\n",
    "    target_variable = variableFromSentence(output_lang,pair[1])\n",
    "    return input_variable,target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_variable,target_variable = variableFromPair(pairs[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "Now that we have defined our model, we need to train it to be able to perform seq2seq translation. The overview of the training process is as follows:\n",
    "\n",
    "1. Initialize hidden_layers with zeros\n",
    "2. Zero grad optimizers for both Encoder and Decoder RNN (Remember - there are 2 RNNs for each iteration)\n",
    "3. Define input and target lengths\n",
    "4. Define loss = 0\n",
    "\n",
    "## EncoderRNN Training\n",
    "\n",
    "1. For each word in the input sentence, pass it through the encoder\n",
    "2. Output of each time-step becomes the input for the next time-step\n",
    "\n",
    "\n",
    "<img src=\"images/lstm2.png\">\n",
    "\n",
    "Please complete the below module as per the steps given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_variable,target_variable,encoder,decoder,encoder_optimizer,decoder_optimizer, criterion,max_length=10):\n",
    "    \n",
    "    # initialize encode hidden\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    # zero-out gradient for encoder and decoder optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # compute input and target length\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \n",
    "    # intialize loss to 0\n",
    "    loss = 0\n",
    "    # define encoder outputs (max_len,encoder.hidden_size) for storing all output from each time step\n",
    "    encoder_outputs = Variable(torch.zeros(max_length,encoder.hidden_size))\n",
    "    \n",
    "    # for each input index\n",
    "    for ei in range(input_length):\n",
    "        #pass it to the encoder with the hidden state\n",
    "        encoder_output,encoder_hidden = encoder(input_variable[ei],encoder_hidden)\n",
    "        encoder_outputs[ei]=encoder_output[0][0]\n",
    "    \n",
    "    # append decoder input with sos-token\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    # decoder hidden will be encoder hidden\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # define teacher_forcing ratio and set flag\n",
    "    use_teacher_forcing = True if random.random()<.5 else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # for each till target length        \n",
    "        for di in range(target_length):\n",
    "            # pass decoder_input,decoder_hidden,encoder_output,encoder_outputs through decoder\n",
    "            decoder_output,decoder_hidden, decoder_attention = decoder(decoder_input,decoder_hidden,encoder_output,encoder_outputs)\n",
    "           # compute loss ,using deoder output and target variable\n",
    "            loss += criterion(decoder_output,target_variable[di])\n",
    "            # set input as targer variable\n",
    "            decoder_input = target_variable[di]\n",
    "    else:   \n",
    "        for di in range(target_length):\n",
    "            # pass input and hidden through the decoder\n",
    "            decoder_output,decoder_hidden, decoder_attention = decoder(decoder_input,decoder_hidden,encoder_output,encoder_outputs)\n",
    "            # find index of maximun using decoder_output probabilities\n",
    "            topv,topi = decoder_output.data.topk(1)\n",
    "            next_index = topi[0][0]\n",
    "            # decoder input is the next variable Tensor\n",
    "            decoder_input = Variable(torch.LongTensor([[next_index]]))\n",
    "            # add to loss.. wait! dont backprop till the decoder computation is complete\n",
    "            loss += criterion(decoder_output,target_variable[di])\n",
    "            # if index is same as end of sentence then break!\n",
    "            if next_index==EOS_token:\n",
    "                break\n",
    "\n",
    "   # back propagate loss\n",
    "    loss.backward()\n",
    "    \n",
    "    # step optimizer\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    #return loss (normalized loss)\n",
    "    return loss.data[0]/target_length\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder,decoder,n_iter,print_every=1000,learning_rate = .01):\n",
    "    plot_loss = []\n",
    "    print_loss = 0\n",
    "    # define optimizers - encoder and decoder opts\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(),lr = learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(),lr = learning_rate)\n",
    "    # generate random pairs..\n",
    "    training_set = [variableFromPair(random.choice(pairs)) for i in range(n_iter)]\n",
    "    # define NLLoss as loss criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    # for number of iterations\n",
    "    for i in range(1,n_iter+1):\n",
    "        # extract the input sentence\n",
    "        train_sentence = training_set[i-1]\n",
    "        # define input and target variable\n",
    "        input_variable = train_sentence[0]\n",
    "        target_variable = train_sentence[1]\n",
    "        # call train utilities\n",
    "        loss = train(input_variable,target_variable,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion)\n",
    "        # add loss\n",
    "        print_loss += loss\n",
    "        \n",
    "        if i%print_every==0:\n",
    "            avg_loss = print_loss/print_every\n",
    "            print (\"Iteration %d and Loss %f\" % (i,avg_loss))\n",
    "            print_loss = 0\n",
    "            plot_loss.append(avg_loss)\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # show loss plot\n",
    "    plt.plot(plot_loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words,hidden_size)\n",
    "decoder = AttentionDecoderRNN(hidden_size,output_lang.n_words)\n",
    "\n",
    "trainIters(encoder,decoder,n_iter=75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluatePair(encoder,decoder,sentence,max_length = 10):\n",
    "    input_variable = variableFromSentence(input_lang,sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_outputs = Variable(torch.zeros(max_length,encoder.hidden_size))\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output,encoder_hidden = encoder(input_variable[ei],encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "    \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoder_words = []\n",
    "    decoder_att = torch.zeros(max_length,max_length)\n",
    "    for di in range(max_length):\n",
    "        decoder_output,decoder_hidden, decoder_attention = decoder(decoder_input,decoder_hidden,encoder_output,encoder_outputs)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        next_index = topi[0][0]\n",
    "        decoder_att[di] = decoder_attention.data\n",
    "        if next_index==EOS_token:\n",
    "            decoder_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoder_words.append(output_lang.index2word[next_index])\n",
    "            \n",
    "        decoder_input = Variable(torch.LongTensor([[next_index]]))\n",
    "    \n",
    "    return decoder_words,decoder_att[:di+1]\n",
    "\n",
    "def evaluate(encoder,decoder,n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print (\"Input: \",pair[0])\n",
    "        print (\"Ground Truth: \",pair[1])\n",
    "        output_words,attention = evaluatePair(encoder,decoder,pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print (\"Translation: \",output_sentence)\n",
    "        print (\"\\n\\n\")\n",
    "        print (attention)\n",
    "        plt.matshow(attention.numpy())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate(encoder,decoder,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluatePair(\n",
    "        encoder, decoder, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
